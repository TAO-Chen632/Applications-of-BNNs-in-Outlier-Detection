{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Initialization settings - Load the packages\n\nLoad the required packages and define the function to fix the random seed","metadata":{}},{"cell_type":"code","source":"# The initialization settings - Load the required packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport tensorflow_probability as tfp\nimport tensorflow.keras as tkeras\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.cluster import DBSCAN\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport random\n\n# Note that 'edward2' is not a built-in Python package of Kaggle.\n# When you first load it, you need to install it using 'pip'.\nimport os\nos.system('pip install edward2')\nimport edward2 as ed2\n\n# Define the function to fix the random seed\ndef set_seed(seed = 0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T11:29:28.564006Z","iopub.execute_input":"2021-12-19T11:29:28.564383Z","iopub.status.idle":"2021-12-19T11:29:48.2709Z","shell.execute_reply.started":"2021-12-19T11:29:28.564297Z","shell.execute_reply":"2021-12-19T11:29:48.269899Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 1 - The exploration on the Wine data set\n\nLoad the Wine data set  \nYou first need to upload this data set to the following path on Kaggle:  \n**'../input/wine-dataset/wine.csv'**  \n\nPerform some initial analyses on Wine data set","metadata":{}},{"cell_type":"code","source":"# Load the Wine data set\n# You first need to upload this data set to the following path:\n# '../input/wine-dataset/wine.csv'\nwine = pd.read_csv('../input/wine-dataset/wine.csv', sep = ',')\ndataset_size = len(wine)\n\n# Fix the random seed\nset_seed(seed = 60)\n\n# Some initial analyses on Wine data set\nprint(wine.info()); display(wine.describe())\nplt.figure(figsize = (12, 8))\nsns.heatmap(wine.corr(), annot = True, cmap = 'seismic',\n            vmin = -1, vmax = 1, center = 0)\nplt.title('Correlation matrix for Wine data set')\ndisplay(wine[['quality']].join(pd.DataFrame({'count' : [1 for i in range(dataset_size)]})).\\\n    groupby('quality').count())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the Wine data set on 2-dimensional space using the Principal Component Analysis (PCA) technique","metadata":{}},{"cell_type":"code","source":"# In order to visualize the Wine data set, I use Principal Component Analysis\n# (PCA) technique to reduce the dimension of the features of this data set.\nmodel_dimredu = PCA(n_components = 2)\nwine_features = wine.drop(['quality'], 1)\nmodel_dimredu.fit(wine_features)\nwine_features_2D = model_dimredu.transform(wine_features)\n\n# I visualize the Wine data set on 2-dimensional space, with the\n# data points classified by wine quality.\nwine_dimredu = pd.concat(\n    [pd.DataFrame(wine_features_2D, columns = ['PCA1', 'PCA2']),\\\n    wine[['quality']].rename(columns = {'quality' : 'Quality'})], axis = 1)\nsns.lmplot(x = 'PCA1', y = 'PCA2', hue = 'Quality', data = wine_dimredu, fit_reg = False)\nplt.title('Visualization of Wine data set on 2-dimensional space')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the data used to train the model and split them into train, validation and test set","metadata":{}},{"cell_type":"code","source":"# Prepare the data used to train the model\n# Prepare the features and target of the Wine data set separately, convert the\n# data set to \"tensorflow.dataset\" type and convert \"wine quality\" to \"float\" type\nfeatures = tf.constant(wine.drop(['quality'], 1))\nlabels = tf.constant(wine[['quality']])\nwine_tfds = tf.data.Dataset.from_tensor_slices((features, labels)).\\\n    map(lambda x, y: (x, tf.cast(y, tf.float64))).\\\n    shuffle(buffer_size = dataset_size).prefetch(buffer_size = dataset_size)\n\n# Split the data set into train, validation and test set, and batch each set\ntrain_size = round(dataset_size*0.8)\nvalidation_size = round(dataset_size*0.1)\ntest_size = dataset_size - train_size - validation_size\nbatch_size = 256\nwine_train = wine_tfds.take(train_size).batch(batch_size)\nwine_validation = wine_tfds.skip(train_size).take(validation_size).batch(validation_size)\nwine_test = wine_tfds.skip(train_size + validation_size).batch(test_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the prior and variational posterior of network weight parameters and define the negative log-likelihood function of the model","metadata":{}},{"cell_type":"code","source":"# Define the prior weight distributions as independent standard normal distributions\ndef prior(kernel_size, bias_size, dtype = None):\n    n = kernel_size + bias_size\n    return tkeras.Sequential([\n        tfp.layers.DistributionLambda(\n            lambda t: tfp.distributions.MultivariateNormalDiag(\n                loc = tf.zeros(n), scale_diag = tf.ones(n))\n        )\n    ])\n\n# Define the variational posterior weight distribution as multivariate Gaussian distribution\n# The trainable parameters for this distribution are the means, variances, and covariances.\ndef posterior(kernel_size, bias_size, dtype = None):\n    n = kernel_size + bias_size\n    return tkeras.Sequential([\n               tfp.layers.VariableLayer(\n                   tfp.layers.MultivariateNormalTriL.params_size(n), dtype = dtype\n               ),\n               tfp.layers.MultivariateNormalTriL(n),\n           ])\n\n# Define the negative log-likelihood function of the model\ndef negative_log_likelihood(y_true, y_pred):\n    return -y_pred.log_prob(y_true)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Construct and train the Bayesian neural network (BNN) model","metadata":{}},{"cell_type":"code","source":"# Specify some model parameters\nkl_loss_weight = 1/train_size\nlearning_rate = 0.001\nnum_epochs = 1000\n\n# Construct the Bayesian neural network model with two hidden layers\nwine_model = tkeras.Sequential([\n    tkeras.layers.Input(shape = (12,)),\n    tkeras.layers.BatchNormalization(),\n    tfp.layers.DenseVariational(\n        units = 8, make_posterior_fn = posterior,\n        make_prior_fn = prior, kl_weight = kl_loss_weight,\n        activation = 'sigmoid'\n    ),\n    tfp.layers.DenseVariational(\n        units = 8, make_posterior_fn = posterior,\n        make_prior_fn = prior, kl_weight = kl_loss_weight,\n        activation = 'sigmoid'\n    ),\n    tkeras.layers.Dense(units = 2),\n    tfp.layers.IndependentNormal(1)\n])\n\n# View the structure of the model\nwine_model.summary()\n\n# Compile the constructed Bayesian neural network\n# We take the negative Evidence Lower Bound (-ELBO) as the loss function,\n# and use the RMSprop optimizer with learning rate being equal to 0.001 to\n# minimize the loss function, and use Mean Square Error (MSE) as the metric\n# to evaluate the accuracy of the model.\nwine_model.compile(\n    optimizer = tkeras.optimizers.RMSprop(learning_rate = learning_rate),\n    loss = negative_log_likelihood,\n    metrics = [tkeras.metrics.mean_squared_error]\n)\n\n# Fit the constructed Bayesian neural network with data\nwine_fit = wine_model.fit(x = wine_train, epochs = num_epochs,\n                          validation_data = wine_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Draw the trend of the loss and the MSE on the train and validation set during the training process respectively","metadata":{}},{"cell_type":"code","source":"# Draw the trend of the loss and the MSE on the train and\n# validation set during the training process respectively\n\n# Prepare the data\ntrain_loss = wine_fit.history['loss']\nval_loss = wine_fit.history['val_loss']\ntrain_eva = wine_fit.history['mean_squared_error']\nval_eva = wine_fit.history['val_mean_squared_error']\nepochs = range(1, num_epochs + 1)\n\n# The trend of loss on the train and validation set\nfig1 = plt.figure(figsize = (5, 3)); ax1 = plt.axes()\nax1.plot(epochs, train_loss, 'b-.', label = 'Training loss')\nax1.plot(epochs, val_loss, 'g-.', label = 'Validation loss')\nax1.xaxis.set_major_locator(plt.MultipleLocator(100))\nax1.set(xlabel = 'Epoch', ylabel = 'Loss',\n        title = 'Training and validation loss')\nax1.legend()\n\n# The trend of the metric (MSE) on the train and validation set\nfig2 = plt.figure(figsize = (5, 3)); ax2 = plt.axes()\nax2.plot(epochs, val_eva, 'g-', label = 'Validation MSE')\nax2.plot(epochs, train_eva, 'b-', label = 'Training MSE')\nax2.xaxis.set_major_locator(plt.MultipleLocator(100))\nax2.set(xlabel = 'Epoch', ylabel = 'Mean squared error',\n        title = 'Training and validation mean squared error')\nax2.legend()\n\n# Evaluate the trained model on both train set and test set respectively\nprint(wine_model.evaluate(wine_train, verbose = 0))\nprint(wine_model.evaluate(wine_test, verbose = 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I take 12 samples from the test set, two samples per quality level (from 3 to 8). Then, I construct and visualize the 95% confidence intervals for the predictions of these selected samples.","metadata":{}},{"cell_type":"code","source":"# Take 12 samples from the test set, two samples per quality level (from 3 to 8)\nfeatures_exa, targets_exa = list(wine_test)[0]\nfeatures_exa = features_exa.numpy()\ntargets_exa = targets_exa.numpy()[:, 0]\nsample_ind = np.array([])\nfor k in range(3, 9):\n    choice = np.random.choice(np.where(targets_exa == k)[0], size = 2)\n    sample_ind = np.concatenate([sample_ind, choice])\nexamples = features_exa[sample_ind.astype('int'), :]\nlabels_exa = targets_exa[sample_ind.astype('int')]\n\n# Compare the prediction means with the true labels\nexamples_mean = wine_model(examples).mean().numpy()\nexamples_std = wine_model(examples).stddev().numpy()\n\n# Construct and visualize the 95% confidence intervals for the predictions\nplt.figure(figsize = (10, 5))\nindex = range(1, 13)\nquality = np.concatenate(np.array([[k, k] for k in range(3, 9)]))\nplt.scatter(index, examples_mean, color = 'red', label = 'Prediction mean')\nplt.scatter(index, labels_exa, color = 'green', label = 'True value')\nplt.scatter(index, examples_mean + 1.96*examples_std,\n            color = 'blue', marker = '_', label = 'Confidence bound')\nplt.scatter(index, examples_mean - 1.96*examples_std,\n            color = 'blue', marker = '_')\nplt.xlabel('True wine quality'); plt.ylabel('Wine quality')\nplt.xticks(ticks = index, labels = quality)\nplt.title('The 95% confidence intervals for the predictions of twelve selected samples')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clear the model and re-train the model with the whole data set","metadata":{}},{"cell_type":"code","source":"# Clear the model and re-train the model with the whole data set\n\n# Update the weight for the KL divergence loss between\n# the surrogate posterior and weight prior\nkl_loss_weight = 1/dataset_size\n\n# Clear the model\nwine_model = tkeras.Sequential([\n    tkeras.layers.Input(shape = (12,)),\n    tkeras.layers.BatchNormalization(),\n    tfp.layers.DenseVariational(\n        units = 8, make_posterior_fn = posterior,\n        make_prior_fn = prior, kl_weight = kl_loss_weight,\n        activation = 'sigmoid'\n    ),\n    tfp.layers.DenseVariational(\n        units = 8, make_posterior_fn = posterior,\n        make_prior_fn = prior, kl_weight = kl_loss_weight,\n        activation = 'sigmoid'\n    ),\n    tkeras.layers.Dense(units = 2),\n    tfp.layers.IndependentNormal(1)\n])\n\n# Re-compile the model with the same settings\nwine_model.compile(\n    optimizer = tkeras.optimizers.RMSprop(learning_rate = learning_rate),\n    loss = negative_log_likelihood,\n    metrics = [tkeras.metrics.mean_squared_error]\n)\n\n# Re-fit the model with the whole data set\nwine_model.fit(x = wine_tfds.batch(batch_size), epochs = num_epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quantify and plot all kinds of uncertainties of the predictions","metadata":{}},{"cell_type":"code","source":"# Quantify all kinds of uncertainties of the predictions\nN = 1000; records = np.zeros((N, dataset_size, 3))\nfor i in range(N):\n    records[i, :, 0] = wine_model(features).mean().numpy()[:, 0]\n    records[i, :, 1] = wine_model(features).variance().numpy()[:, 0]\n    records[i, :, 2] = ((wine_model(features).mean().numpy() - labels.numpy())**2)[:, 0]\nepistemic = np.var(records[:, :, 0], axis = 0)\naleatoric = np.mean(records[:, :, 1], axis = 0)\nmisspecification = np.mean(records[:, :, 2], axis = 0)\nP = 1; Q = 1; R = 1\ncomp_uncer = P*epistemic + Q*aleatoric + R*misspecification\n\n# Plot all kinds of uncertainties\n\n# Plot the distribution of the epistemic uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(epistemic, color = 'blue', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.xlabel('Epistemic uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the epistemic uncertainty')\n\n# Plot the distribution of the aleatoric uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(aleatoric, color = 'green', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.xlabel('Aleatoric uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the aleatoric uncertainty')\n\n# Plot the distribution of the model misspecification uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(misspecification, color = 'red', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.xlabel('Misspecification uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the misspecification uncertainty')\n\n# Plot the distribution of the total prediction uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(comp_uncer, color = 'purple', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.xlabel('Total prediction uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the total prediction uncertainty')\nthreshold = 3\nplt.axvline(threshold, color = 'red')\n\n# Record the information about the index of outliers\nindex = (comp_uncer > threshold).astype('int').tolist()\nwine_BNN = wine_dimredu.join(pd.DataFrame(index, columns = ['indicator'])).\\\n                        join(pd.DataFrame(comp_uncer, columns = ['uncertainty']))\nprint(np.mean(index)); print(np.sum(index))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the observations with high epistemic, aleatoric and model misspecification uncertainty respectievly","metadata":{"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"# Determine a threshold about the uncertainty level\nquantile = 0.95\n\n# Visualize the observations with high epistemic uncertainty\nplt.figure(figsize = (5, 5))\nax1 = plt.axes(projection = '3d')\nepi_index = (epistemic >= np.quantile(epistemic, quantile))\nax1.scatter3D(wine_BNN['PCA1'][np.where(1 - epi_index)[0]],\n              wine_BNN['PCA2'][np.where(1 - epi_index)[0]],\n              wine_BNN['Quality'][np.where(1 - epi_index)[0]],\n              c = 'gray', s = 10, alpha = 0.25)\nax1.scatter3D(wine_BNN['PCA1'][np.where(epi_index)[0]],\n              wine_BNN['PCA2'][np.where(epi_index)[0]],\n              wine_BNN['Quality'][np.where(epi_index)[0]],\n              c = 'red', s = 10 + 200*epistemic[np.where(epi_index)[0]])\nax1.scatter3D([], [], [], c = 'gray', s = 10, label = 'Normal')\nax1.scatter3D([], [], [], c = 'red', s = 10, label = 'High uncertainty')\nax1.set(xlabel = 'PCA1', ylabel = 'PCA2', zlabel = 'Wine quality',\n        title = 'High epistemic uncertainty samples')\nplt.legend()\n\n# Visualize the observations with high aleatoric uncertainty\nplt.figure(figsize = (5, 5))\nax2 = plt.axes(projection = '3d')\nalea_index = (aleatoric >= np.quantile(aleatoric, quantile))\nax2.scatter3D(wine_BNN['PCA1'][np.where(1 - alea_index)[0]],\n              wine_BNN['PCA2'][np.where(1 - alea_index)[0]],\n              wine_BNN['Quality'][np.where(1 - alea_index)[0]],\n              c = 'gray', s = 10, alpha = 0.25)\nax2.scatter3D(wine_BNN['PCA1'][np.where(alea_index)[0]],\n              wine_BNN['PCA2'][np.where(alea_index)[0]],\n              wine_BNN['Quality'][np.where(alea_index)[0]],\n              c = 'red', s = 10 + 10*aleatoric[np.where(alea_index)[0]])\nax2.scatter3D([], [], [], c = 'gray', s = 10, label = 'Normal')\nax2.scatter3D([], [], [], c = 'red', s = 10, label = 'High uncertainty')\nax2.set(xlabel = 'PCA1', ylabel = 'PCA2', zlabel = 'Wine quality',\n        title = 'High aleatoric uncertainty samples')\nplt.legend()\n\n# Visualize the observations with high misspecification uncertainty\nplt.figure(figsize = (5, 5))\nax3 = plt.axes(projection = '3d')\nmis_index = (misspecification >= np.quantile(misspecification, quantile))\nax3.scatter3D(wine_BNN['PCA1'][np.where(1 - mis_index)[0]],\n              wine_BNN['PCA2'][np.where(1 - mis_index)[0]],\n              wine_BNN['Quality'][np.where(1 - mis_index)[0]],\n              c = 'gray', s = 10, alpha = 0.25)\nax3.scatter3D(wine_BNN['PCA1'][np.where(mis_index)[0]],\n              wine_BNN['PCA2'][np.where(mis_index)[0]],\n              wine_BNN['Quality'][np.where(mis_index)[0]],\n              c = 'red', s = 10 + 1.6*misspecification[np.where(mis_index)[0]])\nax3.scatter3D([], [], [], c = 'gray', s = 10, label = 'Normal')\nax3.scatter3D([], [], [], c = 'red', s = 10, label = 'High uncertainty')\nax3.set(xlabel = 'PCA1', ylabel = 'PCA2', zlabel = 'Wine quality',\n        title = 'High misspecification uncertainty samples')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perform the Local Outlier Factor (LOF) method and DBSCAN method on Wine data set","metadata":{}},{"cell_type":"code","source":"# Perform the Local Outlier Factor (LOF) method on Wine data set\nLof = LocalOutlierFactor()\nLof_pre = Lof.fit_predict(wine)\nLof_fac = Lof.negative_outlier_factor_\nwine_LOF = wine_dimredu.join(pd.DataFrame(Lof_pre, columns = ['indicator'])).\\\n                        join(pd.DataFrame(Lof_fac, columns = ['factor']))\n\n# Perform the DBSCAN method on Wine data set\nDBSCAN_model = DBSCAN(eps = 8, min_samples = 5)\nDBSCAN_fit = DBSCAN_model.fit(wine)\nDBSCAN_pre = DBSCAN_fit.labels_\nDBSCAN_noise = (DBSCAN_pre == -1).astype('int')\nwine_DBSCAN = wine_dimredu.join(pd.DataFrame(DBSCAN_noise, columns = ['indicator']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the results of outlier detection using BNN, LOF and DBSCAN method respectively","metadata":{}},{"cell_type":"code","source":"# Visualize the effects of the three outlier detection methods on Wine data set\n\n# The visualization of the effect of Bayesian neural network\nplt.figure(figsize = (5, 5))\nax1 = plt.axes(projection = '3d')\nuncer_outlier = wine_BNN['uncertainty'][wine_BNN['indicator'] == 1]\nax1.scatter3D(wine_BNN['PCA1'][wine_BNN['indicator'] == 0],\n              wine_BNN['PCA2'][wine_BNN['indicator'] == 0],\n              wine_BNN['Quality'][wine_BNN['indicator'] == 0],\n              c = 'gray', s = 10, alpha = 0.25)\nax1.scatter3D(wine_BNN['PCA1'][wine_BNN['indicator'] == 1],\n              wine_BNN['PCA2'][wine_BNN['indicator'] == 1],\n              wine_BNN['Quality'][wine_BNN['indicator'] == 1],\n              c = 'red', s = 10 + 2.5*uncer_outlier)\nax1.scatter3D([], [], [], c = 'gray', s = 10, label = 'Inlier')\nax1.scatter3D([], [], [], c = 'red', s = 10, label = 'Outlier')\nax1.set(xlabel = 'PCA1', ylabel = 'PCA2', zlabel = 'Wine quality',\n        title = 'Outlier detection on Wine data set\\nusing Bayesian neural network')\nplt.legend()\n\n# The visualization of the effect of Local Outlier Factor method\nplt.figure(figsize = (5, 5))\nax2 = plt.axes(projection = '3d')\nax2.scatter3D(wine_LOF['PCA1'][wine_LOF['indicator'] == 1],\n              wine_LOF['PCA2'][wine_LOF['indicator'] == 1],\n              wine_LOF['Quality'][wine_LOF['indicator'] == 1],\n              c = 'gray', s = 10, alpha = 0.25)\nLOF_outlier = wine_LOF['factor'][wine_LOF['indicator'] == -1]\nax2.scatter3D(wine_LOF['PCA1'][wine_LOF['indicator'] == -1],\n              wine_LOF['PCA2'][wine_LOF['indicator'] == -1],\n              wine_LOF['Quality'][wine_LOF['indicator'] == -1],\n              c = 'red', s = 10 - 4*LOF_outlier)\nax2.scatter3D([], [], [], c = 'gray', s = 10, label = 'Inlier')\nax2.scatter3D([], [], [], c = 'red', s = 10, label = 'Outlier')\nax2.set(xlabel = 'PCA1', ylabel = 'PCA2', zlabel = 'Wine quality',\n        title = 'Outlier detection on Wine data set\\nusing Local Outlier Factor method')\nplt.legend()\n\n# The visualization of the effect of DBSCAN method\nplt.figure(figsize = (5, 5))\nax3 = plt.axes(projection = '3d')\nax3.scatter3D(wine_DBSCAN['PCA1'][wine_DBSCAN['indicator'] == 0],\n              wine_DBSCAN['PCA2'][wine_DBSCAN['indicator'] == 0],\n              wine_DBSCAN['Quality'][wine_DBSCAN['indicator'] == 0],\n              c = 'gray', s = 10, alpha = 0.25)\nax3.scatter3D(wine_DBSCAN['PCA1'][wine_DBSCAN['indicator'] == 1],\n              wine_DBSCAN['PCA2'][wine_DBSCAN['indicator'] == 1],\n              wine_DBSCAN['Quality'][wine_DBSCAN['indicator'] == 1],\n              c = 'red', s = 10, label = 'Outlier')\nax3.scatter3D([], [], [], c = 'gray', s = 10, label = 'Inlier')\nax3.set(xlabel = 'PCA1', ylabel = 'PCA2', zlabel = 'Wine quality',\n        title = 'Outlier detection on Wine data set\\nusing DBSCAN method')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 2 - The exploration on the MNIST data set\n\nLoad the MNIST data set  \nYou first need to upload this data set to the following path on Kaggle:  \n**'../input/mnist-dataset/mnist_784.csv'**  \n\nPerform some initial analyses on MNIST data set","metadata":{}},{"cell_type":"code","source":"# Load the MNIST data set and adjust the column name\n# You first need to upload this data set to the following path:\n# '../input/mnist-dataset/mnist_784.csv'\nmnist = pd.read_csv('../input/mnist-dataset/mnist_784.csv', sep = ',')\nmnist.rename(columns = {'class' : 'label'}, inplace = True)\n\n# Fix the random seed\nset_seed(seed = 200)\n\n# Some initial analyses on the MNIST data set\ndataset_size = len(mnist)\nprint(mnist.info()); display(mnist.describe())\ndisplay(mnist[['label']].join(pd.DataFrame({'count' : [1 for i in range(dataset_size)]})).\\\n    groupby('label').count())\n\n# Some initial data preparation for the MNIST\nmnist.iloc[:, :-1] = mnist.drop(['label'], 1)/255","metadata":{"execution":{"iopub.status.busy":"2021-12-19T11:29:57.192219Z","iopub.execute_input":"2021-12-19T11:29:57.192492Z","iopub.status.idle":"2021-12-19T11:30:57.7677Z","shell.execute_reply.started":"2021-12-19T11:29:57.192463Z","shell.execute_reply":"2021-12-19T11:30:57.766665Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I randomly take 120 samples from MNIST data set and visualize these digits.","metadata":{}},{"cell_type":"code","source":"# Randomly take some samples from MNIST data set and visualize these digits\nn_examples = 120\nexamples = np.random.permutation(mnist)[:n_examples, :]\nfeatures_exa = examples[:, :-1].reshape(n_examples, 28, 28)\nlabels_exa = examples[:, -1].astype('int')\n\ncolumns = 15; rows = int(n_examples/columns)\nfigs, axes = plt.subplots(rows, columns, figsize = (columns, rows),\n                          subplot_kw = {'xticks':[], 'yticks':[]},\n                          gridspec_kw = dict(hspace = 0.1, wspace = 0.1))\nplt.suptitle('Display of some handwritten digits in MNIST data set', fontsize = 15, y = 0.95)\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(features_exa[i], cmap = 'binary', interpolation = 'nearest')\n    ax.text(0.05, 0.05, str(labels_exa[i]), transform = ax.transAxes, color = 'green')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(False)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T11:31:07.940927Z","iopub.execute_input":"2021-12-19T11:31:07.941218Z","iopub.status.idle":"2021-12-19T11:31:13.558766Z","shell.execute_reply.started":"2021-12-19T11:31:07.941187Z","shell.execute_reply":"2021-12-19T11:31:13.558136Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the data used to train the model and split them into train, validation and test set","metadata":{}},{"cell_type":"code","source":"# Prepare the data used to train the model\n# Prepare the features and target of MNIST data set separately, and\n# convert the data set to \"tensorflow.dataset\" type\nmnist_onehot = OneHotEncoder()\nmnist_onehot.fit(mnist[['label']].values)\nlabels = mnist_onehot.transform(mnist[['label']].values).A\nfeatures = tf.constant(mnist.loc[:, 'pixel1':'pixel784'].\\\n                       values.reshape(dataset_size, 28, 28, 1))\nlabels = tf.constant(labels)\nmnist_tfds = tf.data.Dataset.from_tensor_slices((features, labels)).\\\n    shuffle(buffer_size = dataset_size).prefetch(buffer_size = dataset_size)\n\n# Split the data set into train, validation and test set\ntrain_size = round(dataset_size*0.85)\nvalidation_size = round(dataset_size*0.075)\ntest_size = dataset_size - train_size - validation_size\nmnist_train = mnist_tfds.take(train_size).batch(train_size)\nmnist_validation = mnist_tfds.skip(train_size).take(validation_size).batch(validation_size)\nmnist_test = mnist_tfds.skip(train_size + validation_size).batch(test_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T11:31:18.241987Z","iopub.execute_input":"2021-12-19T11:31:18.242836Z","iopub.status.idle":"2021-12-19T11:31:19.123141Z","shell.execute_reply.started":"2021-12-19T11:31:18.242796Z","shell.execute_reply":"2021-12-19T11:31:19.122125Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Construct and train the Bayesian convolutional neural network (BCNN) model","metadata":{}},{"cell_type":"code","source":"# Specify some model parameters\nlearning_rate = 0.002\nnum_epochs = 1000\n\n# Define the loss function\n# We still use the negative Evidence Lower Bound as the loss function\ndef negative_ELBO(label_true, label_pred):\n    neg_log_likelihood = -tf.reduce_sum(label_pred.log_prob(label_true))\n    kl = sum(mnist_model.losses)\n    return neg_log_likelihood + kl/train_size\n\n# Construct the Bayesian convolutional neural network model\nmnist_model = tkeras.Sequential([\n    tkeras.layers.Input(shape = (28, 28, 1)),\n    tfp.layers.Convolution2DFlipout(filters = 8, kernel_size = (5, 5),\n                                    padding = \"SAME\", activation = 'relu'),\n    tkeras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n    tfp.layers.Convolution2DFlipout(filters = 16, kernel_size = (5, 5), activation = 'relu'),\n    tkeras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n    tfp.layers.Convolution2DFlipout(filters = 128, kernel_size = (5, 5), activation = 'relu'),\n    tkeras.layers.Flatten(),\n    tkeras.layers.Dropout(0.5),\n    tfp.layers.DenseFlipout(units = 96, activation = 'relu'),\n    tkeras.layers.Dense(units = 10, activation = 'softmax'),\n    tfp.layers.OneHotCategorical(event_size = 10,\n                                 convert_to_tensor_fn = tfp.distributions.Distribution.mode)\n])\n\n# View the structure of the model\nmnist_model.summary()\n\n# Compile the constructed Bayesian convolutional neural network\n# I use the Adam optimizer with learning rate being equal to 0.002 to minimize the\n# loss function, and use the classification accuracy to evaluate the model accuracy.\nmnist_model.compile(\n    optimizer = tkeras.optimizers.Adam(learning_rate = learning_rate),\n    loss = negative_ELBO,\n    metrics = [tkeras.metrics.categorical_accuracy]\n)\n\n# Fit the constructed Bayesian convolutional neural network with data\nmnist_fit = mnist_model.fit(x = mnist_train, epochs = num_epochs,\n                            validation_data = mnist_validation)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T09:06:30.380703Z","iopub.execute_input":"2021-12-15T09:06:30.381224Z","iopub.status.idle":"2021-12-15T09:46:58.089736Z","shell.execute_reply.started":"2021-12-15T09:06:30.381188Z","shell.execute_reply":"2021-12-15T09:46:58.088965Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Draw the trend of the loss and the MSE on the train and validation set during the training process respectively","metadata":{}},{"cell_type":"code","source":"# Draw the trend of the loss and the classification accuracy on the\n# train and validation set during the training process respectively\n\n# Prepare the data\ntrain_loss = mnist_fit.history['loss']\nval_loss = mnist_fit.history['val_loss']\ntrain_eva = mnist_fit.history['categorical_accuracy']\nval_eva = mnist_fit.history['val_categorical_accuracy']\nepochs = range(1, num_epochs + 1)\n\n# The trend of loss on the train and validation set\nfig1 = plt.figure(figsize = (5, 3)); ax1 = plt.axes()\nax1.plot(epochs, train_loss, 'b-.', label = 'Training loss')\nax1.plot(epochs, val_loss, 'g-.', label = 'Validation loss')\nax1.xaxis.set_major_locator(plt.MultipleLocator(250))\nax1.set(xlabel = 'Epoch', ylabel = 'Loss',\n        title = 'Training and validation loss')\nax1.legend()\n\n# The trend of classification accuracy on the train and validation set\nfig2 = plt.figure(figsize = (5, 3)); ax2 = plt.axes()\nax2.plot(epochs, train_eva, 'b-', label = 'Training categorical accuracy')\nax2.plot(epochs, val_eva, 'g-', label = 'Validation categorical accuracy')\nax2.xaxis.set_major_locator(plt.MultipleLocator(250))\nax2.set(xlabel = 'Epoch', ylabel = 'Categorical accuracy',\n        title = 'Training and validation categorical accuracy')\nax2.legend()\n\n# Evaluate the trained model on both train set and test set respectively\nprint(mnist_model.evaluate(mnist_train, verbose = 0))\nprint(mnist_model.evaluate(mnist_test, verbose = 0))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T09:47:30.879775Z","iopub.execute_input":"2021-12-15T09:47:30.880313Z","iopub.status.idle":"2021-12-15T09:47:33.392841Z","shell.execute_reply.started":"2021-12-15T09:47:30.880276Z","shell.execute_reply":"2021-12-15T09:47:33.392169Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clear the model and re-train the model with the whole data set","metadata":{}},{"cell_type":"code","source":"# Clear the model and re-train the model with the whole data set\n\n# Appropriately reduce the data amount a little bit in order to avoid the problem of GPU memory overflow\n# The principle and the implementation process of our method are always the same\nreal_size = dataset_size - 5000\nmnist_real = mnist_tfds.take(real_size).batch(real_size)\n\n# Re-define the loss function in order to update the weight for the\n# KL divergence loss between the surrogate posterior and weight prior\ndef negative_ELBO(label_true, label_pred):\n    neg_log_likelihood = -tf.reduce_sum(label_pred.log_prob(label_true))\n    kl = sum(mnist_model.losses)\n    return neg_log_likelihood + kl/real_size\n\n# Clear the model\nmnist_model = tkeras.Sequential([\n    tkeras.layers.Input(shape = (28, 28, 1)),\n    tfp.layers.Convolution2DFlipout(filters = 8, kernel_size = (5, 5),\n                                    padding = \"SAME\", activation = 'relu'),\n    tkeras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n    tfp.layers.Convolution2DFlipout(filters = 16, kernel_size = (5, 5), activation = 'relu'),\n    tkeras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n    tfp.layers.Convolution2DFlipout(filters = 128, kernel_size = (5, 5), activation = 'relu'),\n    tkeras.layers.Flatten(),\n    tkeras.layers.Dropout(0.5),\n    tfp.layers.DenseFlipout(units = 96, activation = 'relu'),\n    tkeras.layers.Dense(units = 10, activation = 'softmax'),\n    tfp.layers.OneHotCategorical(event_size = 10,\n                                 convert_to_tensor_fn = tfp.distributions.Distribution.mode)\n])\n\n# Re-compile the model with the same settings\nmnist_model.compile(\n    optimizer = tkeras.optimizers.Adam(learning_rate = learning_rate),\n    loss = negative_ELBO,\n    metrics = [tkeras.metrics.categorical_accuracy]\n)\n\n# Re-fit the model with the whole data set\nmnist_model.fit(x = mnist_real, epochs = num_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T05:03:27.76929Z","iopub.execute_input":"2021-12-17T05:03:27.769637Z","iopub.status.idle":"2021-12-17T05:36:37.796312Z","shell.execute_reply.started":"2021-12-17T05:03:27.769605Z","shell.execute_reply":"2021-12-17T05:36:37.795127Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quantify and plot all kinds of uncertainties of the predictions","metadata":{}},{"cell_type":"code","source":"# Quantify all kinds of uncertainties of the predictions\nN = 1000; records = np.zeros((N, real_size, 12))\nfeatures_real = features[:real_size]\nlabels_real = labels[:real_size]\nlabels_conv = np.where(labels_real.numpy())[1]\nfor i in range(N):\n    records[i, :, 0:10] = mnist_model(features_real).mean().numpy()\n    records[i, :, 10] = mnist_model(features_real).entropy().numpy()\n    records[i, :, 11] = -np.sum(np.log(mnist_model(features_real).mean().numpy())*\\\n                                labels_real.numpy(), axis = 1)\nepistemic = 0\nfor i in range(10):\n    epistemic += np.var(records[:, :, i], axis = 0)\naleatoric = np.mean(records[:, :, 10], axis = 0)\nmisspecification = np.mean(records[:, :, 11], axis = 0)\nP = 1/np.std(epistemic); Q = 1/np.std(aleatoric); R = 1/np.std(misspecification);\nW = -(P*np.min(epistemic) + Q*np.min(aleatoric) + R*np.min(misspecification))\ncomp_uncer = P*epistemic + Q*aleatoric + R*misspecification + W\n\n# Plot all kinds of uncertainties\n\n# Plot the distribution of the epistemic uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(epistemic, color = 'blue', bins = 25,\n         weights = np.ones(real_size)/real_size)\nplt.xlabel('Epistemic uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the epistemic uncertainty')\n\n# Plot the distribution of the aleatoric uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(aleatoric, color = 'green', bins = 25,\n         weights = np.ones(real_size)/real_size)\nplt.xlabel('Aleatoric uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the aleatoric uncertainty')\n\n# Plot the distribution of the model misspecification uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(misspecification, color = 'red', bins = 25,\n         weights = np.ones(real_size)/real_size)\nplt.xlabel('Misspecification uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the misspecification uncertainty')\n\n# Plot the distribution of the total prediction uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(comp_uncer, color = 'purple', bins = 25,\n         weights = np.ones(real_size)/real_size)\nplt.xlabel('Total prediction uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the total prediction uncertainty')\nthreshold = 13\nplt.axvline(threshold, color = 'red')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T05:39:43.584304Z","iopub.execute_input":"2021-12-17T05:39:43.584576Z","iopub.status.idle":"2021-12-17T05:51:26.638995Z","shell.execute_reply.started":"2021-12-17T05:39:43.584546Z","shell.execute_reply":"2021-12-17T05:51:26.637938Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the samples with high epistemic, aleatoric and model misspecification uncertainty respectievly","metadata":{}},{"cell_type":"code","source":"# Determine a threshold about the uncertainty level\nquantile = 0.985\n\n# Visualize the samples with high epistemic uncertainty\nlocation = (epistemic > np.quantile(epistemic, quantile))\nindex = np.where(location)[0]; amount = len(index)\ncolumns = 15; rows = int(amount/columns) + 1 \\\n    if amount%columns != 0 else int(amount/columns)\nfigs, axes = plt.subplots(rows, columns, figsize = (columns, rows),\n                          subplot_kw = {'xticks':[], 'yticks':[]},\n                          gridspec_kw = dict(hspace = 0.4, wspace = 0.1))\nplt.suptitle('The samples with high epistemic uncertainty', y = 0.89, fontsize = 15)\nfor i, ax in enumerate(axes.flat):\n    if i < amount:\n        ax.imshow(features_real.numpy()[index[i]], cmap = 'binary', interpolation = 'nearest')\n        ax.text(0.05, 0.05, str(int(labels_conv[index[i]])),\n                transform = ax.transAxes, color = 'green')\n        ax.set_xlabel('{:.5f}'.format(epistemic[index[i]]), color = 'red')\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n    else:\n        ax.axis('off')\n\n# Visualize the samples with high aleatoric uncertainty\nlocation = (aleatoric > np.quantile(aleatoric, quantile))\nindex = np.where(location)[0]; amount = len(index)\ncolumns = 15; rows = int(amount/columns) + 1 \\\n    if amount%columns != 0 else int(amount/columns)\nfigs, axes = plt.subplots(rows, columns, figsize = (columns, rows),\n                          subplot_kw = {'xticks':[], 'yticks':[]},\n                          gridspec_kw = dict(hspace = 0.4, wspace = 0.1))\nplt.suptitle('The samples with high aleatoric uncertainty', y = 0.89, fontsize = 15)\nfor i, ax in enumerate(axes.flat):\n    if i < amount:\n        ax.imshow(features_real.numpy()[index[i]], cmap = 'binary', interpolation = 'nearest')\n        ax.text(0.05, 0.05, str(int(labels_conv[index[i]])),\n                transform = ax.transAxes, color = 'green')\n        ax.set_xlabel('{:.5f}'.format(aleatoric[index[i]]), color = 'red')\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n    else:\n        ax.axis('off')\n\n# Visualize the samples with high misspecification uncertainty\nlocation = (misspecification > np.quantile(misspecification, quantile))\nindex = np.where(location)[0]; amount = len(index)\ncolumns = 15; rows = int(amount/columns) + 1 \\\n    if amount%columns != 0 else int(amount/columns)\nfigs, axes = plt.subplots(rows, columns, figsize = (columns, rows),\n                          subplot_kw = {'xticks':[], 'yticks':[]},\n                          gridspec_kw = dict(hspace = 0.4, wspace = 0.1))\nplt.suptitle('The samples with high misspecification uncertainty', y = 0.89, fontsize = 15)\nfor i, ax in enumerate(axes.flat):\n    if i < amount:\n        ax.imshow(features_real.numpy()[index[i]], cmap = 'binary', interpolation = 'nearest')\n        ax.text(0.05, 0.05, str(int(labels_conv[index[i]])),\n                transform = ax.transAxes, color = 'green')\n        ax.set_xlabel('{:.4f}'.format(misspecification[index[i]]), color = 'red')\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n    else:\n        ax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T05:53:55.260515Z","iopub.execute_input":"2021-12-17T05:53:55.260821Z","iopub.status.idle":"2021-12-17T06:01:42.091629Z","shell.execute_reply.started":"2021-12-17T05:53:55.260792Z","shell.execute_reply":"2021-12-17T06:01:42.089127Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the result of outlier detection on MNIST data set using BCNN","metadata":{}},{"cell_type":"code","source":"# Record the information about the index of outliers\nlocation = (comp_uncer > threshold)\nindex = np.where(location)[0]\nn_outliers = len(index)\nprint(np.mean(location)); print(n_outliers)\n\n# Visualize the result of outlier detection on MNIST data set using BCNN\ncolumns = 15; rows = int(n_outliers/columns) + 1 \\\n    if n_outliers%columns != 0 else int(n_outliers/columns)\nfigs, axes = plt.subplots(rows, columns, figsize = (columns, rows),\n                          subplot_kw = {'xticks':[], 'yticks':[]},\n                          gridspec_kw = dict(hspace = 0.4, wspace = 0.1))\nplt.suptitle('Outlier detection on MNIST data set using BCNN', y = 0.89, fontsize = 15)\nfor i, ax in enumerate(axes.flat):\n    if i < n_outliers:\n        ax.imshow(features_real.numpy()[index[i]], cmap = 'binary', interpolation = 'nearest')\n        ax.text(0.05, 0.05, str(int(labels_conv[index[i]])),\n                transform = ax.transAxes, color = 'green')\n        ax.set_xlabel('{:.2f}'.format(comp_uncer[index[i]]), color = 'red')\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n    else:\n        ax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:09:55.557733Z","iopub.execute_input":"2021-12-17T06:09:55.558121Z","iopub.status.idle":"2021-12-17T06:14:52.854604Z","shell.execute_reply.started":"2021-12-17T06:09:55.558079Z","shell.execute_reply":"2021-12-17T06:14:52.853613Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perform outlier detection on MNIST data set using LOF and DBSCAN method respectively, and visualize the results of these two methods","metadata":{}},{"cell_type":"code","source":"# Outlier detection on MNIST data set using Local Outlier Factor method\nLof = LocalOutlierFactor(); offset = -1.5\nLof.fit(mnist)\nLof_fac = Lof.negative_outlier_factor_\nLof_pre = (Lof_fac < offset).astype('int')\nindex_out = (Lof_pre == 1)\nn_outliers = sum(index_out)\noutliers_feature = mnist[index_out].drop('label', 1).\\\n                   values.reshape(n_outliers, 28, 28)\noutliers_label = mnist[index_out]['label'].values\n\n# Visualize the result of outlier detection on MNIST data set using LOF method\ncolumns = 15; rows = int(n_outliers/columns) + 1 \\\n    if n_outliers%columns != 0 else int(n_outliers/columns)\nfigs, axes = plt.subplots(rows, columns, figsize = (columns, rows),\n                          subplot_kw = {'xticks':[], 'yticks':[]},\n                          gridspec_kw = dict(hspace = 0.4, wspace = 0.1))\nplt.suptitle('Outlier detection on MNIST data set using LOF method', y = 0.9, fontsize = 15)\nfor i, ax in enumerate(axes.flat):\n    if i < n_outliers:\n        ax.imshow(outliers_feature[i], cmap = 'binary', interpolation = 'nearest')\n        ax.text(0.05, 0.05, str(outliers_label[i]),\n                transform = ax.transAxes, color = 'green')\n        ax.set_xlabel('{:.2f}'.format(-Lof_fac[np.where(index_out)[0][i]]), color = 'red')\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n    else:\n        ax.axis('off')\n\n# Outlier detection on MNIST data set using DBSCAN method\nDBSCAN_model = DBSCAN(eps = 7.2, min_samples = 8)\nDBSCAN_fit = DBSCAN_model.fit(mnist)\nDBSCAN_pre = DBSCAN_fit.labels_\nindex_noise = (DBSCAN_pre == -1); n_noise = sum(index_noise)\nnoise_feature = mnist[index_noise].drop('label', 1).\\\n                values.reshape(n_noise, 28, 28)\nnoise_label = mnist[index_noise]['label'].values\n\n# Visualize the result of outlier detection on MNIST data set using DBSCAN method\ncolumns = 15; rows = int(n_noise/columns) + 1 \\\n    if n_noise%columns != 0 else int(n_noise/columns)\nfigs, axes = plt.subplots(rows, columns, figsize = (columns, rows),\n                          subplot_kw = {'xticks':[], 'yticks':[]},\n                          gridspec_kw = dict(hspace = 0.1, wspace = 0.1))\nplt.suptitle('Outlier detection on MNIST data set using DBSCAN method', y = 0.9, fontsize = 15)\nfor i, ax in enumerate(axes.flat):\n    if i < n_noise:\n        ax.imshow(noise_feature[i], cmap = 'binary', interpolation = 'nearest')\n        ax.text(0.05, 0.05, str(noise_label[i]),\n                transform = ax.transAxes, color = 'green')\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n    else:\n        ax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:47:52.191195Z","iopub.execute_input":"2021-12-18T06:47:52.191615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 3 - The exploration on the Taxi data set\n\nLoad the Taxi data set  \nYou first need to upload this data set to the following path on Kaggle:  \n**'../input/taxi-dataset/taxi.csv'**  \n\nPerform some initial analyses on Taxi data set and remove the seasonal variation of Taxi data set","metadata":{}},{"cell_type":"code","source":"# Load the Taxi data set and use the 'timestamp' column as index\n# You first need to upload this data set to the following path:\n# '../input/taxi-dataset/taxi.csv'\ntaxi = pd.read_csv('../input/taxi-dataset/taxi.csv',\n                   index_col = 'timestamp', parse_dates = True)\ntaxi.index.freq = '30T'\n\n# Fix the random seed\nset_seed(seed = 120)\n\n# Some initial analyses on Taxi data set\nprint(taxi.info()); display(taxi.describe())\ntaxi.plot(figsize = (7.2, 3.6), xlabel = 'Date', ylabel = 'Taxi passengers\\' count',\n          title = 'Counts of taxi passengers in New-York city').legend_.remove()\n\n# Remove the seasonal variation of Taxi data set\nperiod = 336\nmyfilter = np.hstack([1/(2*period), np.array([1/period for i in range(period - 1)]),\n                      1/(2*period)])\ntaxi_decom = seasonal_decompose(taxi, filt = myfilter, period = period,\n                                extrapolate_trend = 'freq')\ntaxi_DeSeason = taxi_decom.observed - taxi_decom.seasonal\ndisplay(taxi_DeSeason.describe())\n\n# Visualize the Taxi data set after removing seasonal variation\nplt.figure(figsize = (7.2, 3.6))\nplt.plot(taxi_DeSeason.index, taxi_DeSeason.values)\nplt.xlabel('Date'); plt.ylabel('Taxi passengers\\' count')\nplt.title('Counts of taxi passengers after removing seasonal variation')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the data used to train the model and split them into train, validation and test set","metadata":{}},{"cell_type":"code","source":"# Prepare the data used to train the model\n# Prepare the features and target of Taxi data set separately, and\n# convert the data set to \"tensorflow.dataset\" type\ntime = (taxi.index.values - np.datetime64('2014-07-01T00:00:00'))/np.timedelta64(1, '30m')\ntaxi_data = np.vstack([time, taxi_DeSeason.values]).T\ndataset_size = len(taxi_data) - 1\nlength = 24\nfeatures = np.zeros((dataset_size, length, 2))\nfor i in range(dataset_size):\n    if i < length:\n        features[i] = np.vstack([taxi_data[[0 for k in range(length - i - 1)]],\n                                 taxi_data[[k for k in range(i + 1)]]])\n    else:\n        features[i] = taxi_data[(i - length + 1):(i + 1)]\nfeatures = tf.constant(features)\nlabels = tf.constant(taxi_DeSeason.values[1:])\ntaxi_tfds = tf.data.Dataset.from_tensor_slices((features, labels)).\\\n    map(lambda x, y: (x, tf.cast(y, tf.float64))).\\\n    prefetch(buffer_size = dataset_size)\n\n# Split the data set into train, validation and test set\ntrain_size = round(dataset_size*0.8)\nvalidation_size = round(dataset_size*0.1)\ntest_size = dataset_size - train_size - validation_size\ntaxi_tfds_veri = taxi_tfds.shuffle(buffer_size = dataset_size)\ntaxi_train = taxi_tfds_veri.take(train_size).batch(train_size)\ntaxi_validation = taxi_tfds_veri.skip(train_size).take(validation_size).batch(validation_size)\ntaxi_test = taxi_tfds_veri.skip(train_size + validation_size).batch(test_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Construct and train the Bayesian LSTM neural network (BLSTMNN) model","metadata":{}},{"cell_type":"code","source":"# Specify some model parameters\nnum_epochs = 5000\nlearning_rate = 0.5\n\n# Define the loss function\n# We still use the negative Evidence Lower Bound (-ELBO) as the loss function.\ndef negative_ELBO(label_true, label_pred):\n    neg_log_likelihood = -tf.reduce_sum(label_pred.log_prob(label_true))\n    kl = sum(taxi_model.losses)/train_size\n    return neg_log_likelihood + kl\n\n# Construct the Bayesian LSTM neural network (BLSTMNN) model\nBLSTM_layer1 = ed2.layers.LSTMCellFlipout(8, activation = 'sigmoid')\nBLSTM_layer2 = ed2.layers.LSTMCellFlipout(16, activation = 'sigmoid')\ntaxi_model = tkeras.Sequential([\n    tkeras.layers.Input(shape = (length, 2)),\n    tkeras.layers.BatchNormalization(),\n    tkeras.layers.RNN(cell = BLSTM_layer1, return_sequences = True),\n    tkeras.layers.RNN(cell = BLSTM_layer2),\n    tkeras.layers.Dense(units = 2),\n    tfp.layers.IndependentNormal(1)\n])\n\n# View the structure of the model\ntaxi_model.summary()\n\n# Compile the constructed Bayesian LSTM neural network\n# I use the RMSprop optimizer with learning rate being equal to 0.5 to\n# minimize the loss function, and use Mean Square Error (MSE) as the metric\n# to evaluate the accuracy of the model.\ntaxi_model.compile(\n    optimizer = tkeras.optimizers.RMSprop(learning_rate = learning_rate),\n    loss = negative_ELBO,\n    metrics = [tkeras.metrics.mean_squared_error]\n)\n\n# Fit the constructed Bayesian LSTM neural network with data\ntaxi_fit = taxi_model.fit(x = taxi_train, epochs = num_epochs,\n                          validation_data = taxi_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Draw the trend of the loss and the MSE on the train and validation set during the training process respectively","metadata":{}},{"cell_type":"code","source":"# Draw the trend of the loss and the MSE on the train and\n# validation set during the training process respectively\n\n# Prepare the data\ntrain_loss = np.array(taxi_fit.history['loss'])\nval_loss = np.array(taxi_fit.history['val_loss'])\ntrain_eva = np.array(taxi_fit.history['mean_squared_error'])\nval_eva = np.array(taxi_fit.history['val_mean_squared_error'])\ninits = 10\nepochs = np.array(range(inits, len(train_loss)))\n\n# The trend of loss on the train and validation set\nfig1 = plt.figure(figsize = (5, 3)); ax1 = plt.axes()\nax1.plot(epochs + 1, train_loss[epochs], 'b-.', label = 'Training loss')\nax1.plot(epochs + 1, val_loss[epochs], 'g-.', label = 'Validation loss')\nax1.set(xlabel = 'Epoch', ylabel = 'Loss',\n        title = 'Training and validation loss')\nax1.legend()\n\n# The trend of the metric (MSE) on the train and validation set\nfig2 = plt.figure(figsize = (5, 3)); ax2 = plt.axes()\nax2.plot(epochs + 1, val_eva[epochs], 'g-', label = 'Validation MSE')\nax2.plot(epochs + 1, train_eva[epochs], 'b-', label = 'Training MSE')\nax2.set(xlabel = 'Epoch', ylabel = 'Mean squared error',\n        title = 'Training and validation MSE')\nax2.legend()\n\n# Evaluate the trained model on both train set and test set respectively\nprint(taxi_model.evaluate(taxi_train, verbose = 0))\nprint(taxi_model.evaluate(taxi_test, verbose = 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I take 10 samples from the test set. Then, I construct and visualize the 95% confidence intervals for the predictions of these samples.","metadata":{}},{"cell_type":"code","source":"# Take 10 samples from the test set\nnum_exa = 10\nfeatures_exa, targets_exa = list(taxi_test.unbatch().batch(num_exa))[0]\nfeatures_exa = features_exa.numpy()\ntargets_exa = targets_exa.numpy()\n\n# Compare the prediction means with the true labels\nexamples_mean = taxi_model(features_exa).mean().numpy()\nexamples_std = taxi_model(features_exa).stddev().numpy()\n\n# Construct and visualize the 95% confidence intervals for the predictions\nplt.figure(figsize = (10, 5))\nindex = range(1, num_exa + 1)\nplt.scatter(index, examples_mean, color = 'red', label = 'Prediction mean')\nplt.scatter(index, targets_exa, color = 'green', label = 'True value')\nplt.scatter(index, examples_mean + 1.96*examples_std,\n            color = 'blue', marker = '_', label = 'Confidence bound')\nplt.scatter(index, examples_mean - 1.96*examples_std,\n            color = 'blue', marker = '_')\nplt.xlabel('Sample index'); plt.ylabel('Taxi passengers\\' count')\nplt.title('The 95% confidence intervals for the predictions of ten samples')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clear the model and re-train the model with the whole data set","metadata":{}},{"cell_type":"code","source":"# Clear the model and re-train the model with the whole data set\n\n# Re-define the loss function in order to update the weight for the\n# KL divergence loss between the surrogate posterior and weight prior\ndef negative_ELBO(label_true, label_pred):\n    neg_log_likelihood = -tf.reduce_sum(label_pred.log_prob(label_true))\n    kl = sum(taxi_model.losses)\n    return neg_log_likelihood + kl/dataset_size\n\n# Clear the model\nBLSTM_layer1 = ed2.layers.LSTMCellFlipout(8, activation = 'sigmoid')\nBLSTM_layer2 = ed2.layers.LSTMCellFlipout(16, activation = 'sigmoid')\ntaxi_model = tkeras.Sequential([\n    tkeras.layers.Input(shape = (length, 2)),\n    tkeras.layers.BatchNormalization(),\n    tkeras.layers.RNN(cell = BLSTM_layer1, return_sequences = True),\n    tkeras.layers.RNN(cell = BLSTM_layer2),\n    tkeras.layers.Dense(units = 2),\n    tfp.layers.IndependentNormal(1)\n])\n\n# Re-compile the model with the same settings\ntaxi_model.compile(\n    optimizer = tkeras.optimizers.RMSprop(learning_rate = learning_rate),\n    loss = negative_ELBO,\n    metrics = [tkeras.metrics.mean_squared_error]\n)\n\n# Re-fit the model with the whole data set\ntaxi_model.fit(x = taxi_tfds.batch(dataset_size), epochs = num_epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quantify and plot all kinds of uncertainties of the predictions","metadata":{}},{"cell_type":"code","source":"# Quantify all kinds of uncertainties of the predictions\nN = 1000; records = np.zeros((N, dataset_size, 3))\nfor i in range(N):\n    records[i, :, 0] = taxi_model(features).mean().numpy()[:, 0]\n    records[i, :, 1] = taxi_model(features).variance().numpy()[:, 0]\n    records[i, :, 2] = (taxi_model(features).mean().numpy()[:, 0] - labels.numpy())**2\nepistemic = np.var(records[:, :, 0], axis = 0)\naleatoric = np.mean(records[:, :, 1], axis = 0)\nmisspecification = np.mean(records[:, :, 2], axis = 0)\nP = 0; Q = 1/np.std(aleatoric); R = 6/np.std(misspecification)\nW = -(Q*np.min(aleatoric) + R*np.min(misspecification))\ncomp_uncer = P*epistemic + Q*aleatoric + R*misspecification + W\n\n# Plot all kinds of uncertainties\n\n# Plot the distribution of the epistemic uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(epistemic, color = 'blue', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.ticklabel_format(style = 'sci', scilimits = (0, 4), axis = 'x')\nplt.xlabel('Epistemic uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the epistemic uncertainty')\n\n# Plot the distribution of the aleatoric uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(aleatoric, color = 'green', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.xlim(pow(10, 6))\nplt.xlabel('Aleatoric uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the aleatoric uncertainty')\n\n# Plot the distribution of the model misspecification uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(misspecification, color = 'red', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.xlabel('Misspecification uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the misspecification uncertainty')\n\n# Plot the distribution of the total prediction uncertainty\nplt.figure(figsize = (5, 3))\nplt.hist(comp_uncer, color = 'purple', bins = 25,\n         weights = np.ones(dataset_size)/dataset_size)\nplt.xlabel('Total prediction uncertainty')\nplt.ylabel('Frenquency')\nplt.title('The distribution of the total prediction uncertainty')\nthreshold = np.quantile(comp_uncer, 0.975)\nplt.axvline(threshold, color = 'red')\n\n# Adjust the vectors that contain all kinds of uncertainties\n# in order to facilitate performing outlier detection\nepistemic = np.hstack([0, epistemic])\naleatoric = np.hstack([0, aleatoric])\nmisspecification = np.hstack([0, misspecification])\ncomp_uncer = np.hstack([0, comp_uncer])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the observations with high epistemic, aleatoric and model misspecification uncertainty respectievly","metadata":{}},{"cell_type":"code","source":"# Determine a threshold about the uncertainty level\nquantile = 0.975\n\n# Visualize the observations with high epistemic uncertainty\nindex = (epistemic > np.quantile(epistemic, quantile))\nhigh_epi = taxi_DeSeason[index]\nnorm_epi = taxi_DeSeason[(1 - index).astype('bool')]\nfig = plt.figure(figsize = (7.2, 3.6)); ax = plt.axes()\nax.scatter(norm_epi.index, norm_epi.values, label = 'Normal')\nax.scatter(high_epi.index, high_epi.values, color = 'red',\n           s = plt.rcParams['lines.markersize']**2 + 3*epistemic[index]/pow(10, 5))\nax.scatter([], [], color = 'red', label = 'High uncertainty')\nax.set(xlabel = 'Time', ylabel = 'Taxi passengers\\' count',\n       title = 'The observations with high epistemic uncertainty')\nplt.legend()\n\n# Visualize the observations with high aleatoric uncertainty\nindex = (aleatoric > np.quantile(aleatoric, quantile))\nhigh_alea = taxi_DeSeason[index]\nnorm_alea = taxi_DeSeason[(1 - index).astype('bool')]\nfig = plt.figure(figsize = (7.2, 3.6)); ax = plt.axes()\nax.scatter(norm_alea.index, norm_alea.values, label = 'Normal')\nax.scatter(high_alea.index, high_alea.values, color = 'red',\n           s = plt.rcParams['lines.markersize']**2 + 4*aleatoric[index]/pow(10, 6))\nax.scatter([], [], color = 'red', label = 'High uncertainty')\nax.set(xlabel = 'Time', ylabel = 'Taxi passengers\\' count',\n       title = 'The observations with high aleatoric uncertainty')\nplt.legend()\n\n# Visualize the observations with high model misspecification uncertainty\nindex = (misspecification > np.quantile(misspecification, quantile))\nhigh_mis = taxi_DeSeason[index]\nnorm_mis = taxi_DeSeason[(1 - index).astype('bool')]\nfig = plt.figure(figsize = (7.2, 3.6)); ax = plt.axes()\nax.scatter(norm_mis.index, norm_mis.values, label = 'Normal')\nax.scatter(high_mis.index, high_mis.values, color = 'red',\n           s = plt.rcParams['lines.markersize']**2 + 3*misspecification[index]/pow(10, 8))\nax.scatter([], [], color = 'red', label = 'High uncertainty')\nax.set(xlabel = 'Time', ylabel = 'Taxi passengers\\' count',\n       title = 'The observations with high misspecification uncertainty')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the result of outlier detection on Taxi data set using BLSTMNN","metadata":{}},{"cell_type":"code","source":"# Record the information about the index of outliers\nthreshold = np.quantile(comp_uncer, 0.975)\nindex = (comp_uncer > threshold)\nn_outliers = np.sum(index)\nprint(np.mean(index)); print(n_outliers)\n\n# Visualize the result of outlier detection on Taxi data set\n# using Bayesian LSTM neural network\noutliers = taxi_DeSeason[index]\ninliers = taxi_DeSeason[(1 - index).astype('bool')]\nfig = plt.figure(figsize = (7.2, 3.6)); ax = plt.axes()\nax.scatter(inliers.index, inliers.values, label = 'Inliers')\nax.scatter(outliers.index, outliers.values, color = 'red',\n           s = plt.rcParams['lines.markersize']**2 + comp_uncer[index]/4)\nax.scatter([], [], color = 'red', label = 'Outliers')\nax.set(xlabel = 'Time', ylabel = 'Taxi passengers\\' count',\n       title = 'Counts of taxi passengers in New-York after removing seasonality')\nplt.legend()\n\n# Visualize the duration of the periods experiencing extremely high and extremely low\n# taxi passenger numbers per day in New-York city respectively, and compare the dates\n# of these extreme periods with the dates of special events happened in New York\n\n# Prepare the data that we need\ntaxi_count = taxi.copy(); middle = 15000\ntaxi_count['value'] = taxi_DeSeason.values\nlarge = []; small = []\nfor i in range(dataset_size + 1):\n    x = 1 if (index[i] and taxi_DeSeason.values[i] > middle) else 0\n    large.append(x)\n    x = 1 if (index[i] and taxi_DeSeason.values[i] < middle) else 0\n    small.append(x)\ntaxi_count['count_large'] = large\ntaxi_count['count_small'] = small\ntaxi_count = taxi_count.resample('D').sum().\\\n    apply(lambda x : 0.5*x).rename(columns = {'value' : 'busyness'})\n\n# Visualize the duration of the extreme periods per day, and compare the\n# dates of these extreme periods with the dates of special events in New-York\nfig = plt.figure(figsize = (7.2, 3.6)); ax = plt.axes()\nax.plot(taxi_count.index, taxi_count['count_large'],\n        color = 'red', label = 'Extremely high period')\nax.plot(taxi_count.index, taxi_count['count_small'],\n        color = 'blue', label = 'Extremely low period')\nevents = ['Independence Day', 'School opening day', 'New-York marathon',\n          'Thanksgiving Day', 'Christmas', 'New Year\\'s Day', 'A snow storm']\ndates = [pd.Timestamp('2014-7-4'), pd.Timestamp('2014-9-1'),\n         pd.Timestamp('2014-11-2'), pd.Timestamp('2014-11-27'),\n         pd.Timestamp('2014-12-25'), pd.Timestamp('2015-1-1'),\n         pd.Timestamp('2015-1-26')]\ncolors = ['green', 'purple', 'yellow', 'brown', 'fuchsia', 'orange', 'cyan']\nfor event, date, color in zip(events, dates, colors):\n    ax.axvline(date, label = event, color = color, linestyle = '--')\nax.set(xlabel = 'Date', ylabel = 'Period length (Hour)',\n       title = 'Duration of extreme periods per day in New-York city')\nplt.legend(bbox_to_anchor = (1.03, 0.5), loc = 6, borderaxespad = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perform outlier detection on Taxi data set using LOF and DBSCAN method respectively, and visualize the results of these two methods","metadata":{}},{"cell_type":"code","source":"# Prepare data for the LOF method and DBSCAN method\ndataset_size = len(taxi_DeSeason)\ntaxi_detect = pd.DataFrame(\n    np.array([range(dataset_size), taxi_DeSeason.values]).T,\n    columns = ['time', 'counts']\n)\n\n# Outlier detection on Taxi data set using Local Outlier Factor method\nLof = LocalOutlierFactor(); offset_ = -1.45\nLof.fit(taxi_detect)\nLof_fac = Lof.negative_outlier_factor_\nLof_pre = -(Lof_fac < offset_).astype('int')\nindex_out = (Lof_pre == -1); index_in = (1 - index_out).astype('bool')\noutliers = taxi_DeSeason[index_out]; inliers = taxi_DeSeason[index_in]\n\n# Visualize the result of outlier detection on Taxi data set using LOF method\nfig = plt.figure(figsize = (7.2, 3.6)); ax = plt.axes()\nax.scatter(inliers.index, inliers.values, c = Lof_pre[index_in],\n           cmap = plt.cm.Dark2, label = 'Inliers')\nax.scatter(outliers.index, outliers.values, color = 'red',\n           s = plt.rcParams['lines.markersize']**2 - 6*Lof_fac[index_out])\nax.scatter([], [], color = 'red', label = 'Outliers')\nax.set(xlabel = 'Time', ylabel = 'Taxi passengers\\' count',\n       title = 'Counts of taxi passengers in New-York after removing seasonality')\nplt.legend()\n\n# Outlier detection on Taxi data set using DBSCAN method\nDBSCAN_model = DBSCAN(eps = 380, min_samples = 20)\nDBSCAN_fit = DBSCAN_model.fit(taxi_detect)\nDBSCAN_pre = DBSCAN_fit.labels_\nindex_noise = (DBSCAN_pre == -1); index_in = (1 - index_noise).astype('bool')\nnoise = taxi_DeSeason[index_noise]; inliers = taxi_DeSeason[index_in]\n\n# Visualize the result of outlier detection on Taxi data set using DBSCAN method\nfig = plt.figure(figsize = (7.2, 3.6)); ax = plt.axes()\nax.scatter(inliers.index, inliers.values, c = DBSCAN_pre[index_in],\n           cmap = plt.cm.Dark2, label = 'Inliers')\nax.scatter(noise.index, noise.values, color = 'red', label = 'Outliers')\nax.set(xlabel = 'Time', ylabel = 'Taxi passengers\\' count',\n       title = 'Counts of taxi passengers in New-York after removing seasonality')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}